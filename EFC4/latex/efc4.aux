\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {paragraph}{The Jupyter notebook related to this section with the results presented here can be opened in Google Colab environment with following link:\\}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Training results and two study cases}{2}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.1}Maze 1}{2}{subsubsection.8.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Maze 1\relax }}{2}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:maze1}{{2}{2}{Maze 1\relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Training results summary for maze 1\relax }}{2}{table.caption.5}\protected@file@percent }
\newlabel{tab:maze1-results}{{1}{2}{Training results summary for maze 1\relax }{table.caption.5}{}}
\newlabel{fig:maze1-case1}{{3a}{2}{Maze 1 - Study case 1\relax }{figure.caption.6}{}}
\newlabel{sub@fig:maze1-case1}{{a}{2}{Maze 1 - Study case 1\relax }{figure.caption.6}{}}
\newlabel{fig:maze1-case2}{{3b}{2}{Maze 1 - Study case 2\relax }{figure.caption.6}{}}
\newlabel{sub@fig:maze1-case2}{{b}{2}{Maze 1 - Study case 2\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.2}Maze 2}{3}{subsubsection.8.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Maze 2\relax }}{3}{figure.caption.7}\protected@file@percent }
\newlabel{fig:maze2}{{4}{3}{Maze 2\relax }{figure.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Training results summary for maze 2\relax }}{3}{table.caption.8}\protected@file@percent }
\newlabel{tab:maze2-results}{{2}{3}{Training results summary for maze 2\relax }{table.caption.8}{}}
\newlabel{fig:maze2-case1}{{5a}{3}{Maze 2 - Study case 1\relax }{figure.caption.9}{}}
\newlabel{sub@fig:maze2-case1}{{a}{3}{Maze 2 - Study case 1\relax }{figure.caption.9}{}}
\newlabel{fig:maze2-case2}{{5b}{3}{Maze 2 - Study case 2\relax }{figure.caption.9}{}}
\newlabel{sub@fig:maze2-case2}{{b}{3}{Maze 2 - Study case 2\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Q-value for three different states}{4}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1}Maze 1 - Study case 1}{4}{subsubsection.8.2.1}\protected@file@percent }
\newlabel{fig:maze1-case1-states}{{6a}{4}{Maze 1: Study case 1 \vspace {12mm}\relax }{figure.caption.10}{}}
\newlabel{sub@fig:maze1-case1-states}{{a}{4}{Maze 1: Study case 1 \vspace {12mm}\relax }{figure.caption.10}{}}
\newlabel{fig:maze1-case1-state1}{{6b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.6266 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4188 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.0743 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0651 \relax }{figure.caption.10}{}}
\newlabel{sub@fig:maze1-case1-state1}{{b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.6266 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4188 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.0743 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0651 \relax }{figure.caption.10}{}}
\newlabel{fig:maze1-case1-state2}{{6c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.4398 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4012 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.2719 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.1840 \relax }{figure.caption.10}{}}
\newlabel{sub@fig:maze1-case1-state2}{{c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.4398 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4012 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.2719 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.1840 \relax }{figure.caption.10}{}}
\newlabel{fig:maze1-case1-state3}{{6d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.0811 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.0670 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.4976 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0538 \relax }{figure.caption.10}{}}
\newlabel{sub@fig:maze1-case1-state3}{{d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.0811 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.0670 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.4976 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0538 \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2}Maze 1 - Study case 2}{4}{subsubsection.8.2.2}\protected@file@percent }
\newlabel{fig:maze1-case2-states}{{7a}{4}{Maze 1: Study case 2 \vspace {12mm}\relax }{figure.caption.11}{}}
\newlabel{sub@fig:maze1-case2-states}{{a}{4}{Maze 1: Study case 2 \vspace {12mm}\relax }{figure.caption.11}{}}
\newlabel{fig:maze1-case2-state1}{{7b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.3038 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4816 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.8406 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.4413 \relax }{figure.caption.11}{}}
\newlabel{sub@fig:maze1-case2-state1}{{b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.3038 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4816 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.8406 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.4413 \relax }{figure.caption.11}{}}
\newlabel{fig:maze1-case2-state2}{{7c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: 0.3047 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: 0.6444 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.9281 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0919 \relax }{figure.caption.11}{}}
\newlabel{sub@fig:maze1-case2-state2}{{c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: 0.3047 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: 0.6444 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.9281 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0919 \relax }{figure.caption.11}{}}
\newlabel{fig:maze1-case2-state3}{{7d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: 0.3186 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: 0.6454 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -1.9548 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 1.0120 \relax }{figure.caption.11}{}}
\newlabel{sub@fig:maze1-case2-state3}{{d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: 0.3186 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: 0.6454 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -1.9548 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 1.0120 \relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3}Maze 2 - Study case 1}{4}{subsubsection.8.2.3}\protected@file@percent }
\newlabel{fig:maze2-case1-states}{{8a}{4}{Maze 1: Study case 1 \vspace {12mm}\relax }{figure.caption.12}{}}
\newlabel{sub@fig:maze2-case1-states}{{a}{4}{Maze 1: Study case 1 \vspace {12mm}\relax }{figure.caption.12}{}}
\newlabel{fig:maze2-case1-state1}{{8b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.5747 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4207 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.4067 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.3697 \relax }{figure.caption.12}{}}
\newlabel{sub@fig:maze2-case1-state1}{{b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.5747 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.4207 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.4067 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.3697 \relax }{figure.caption.12}{}}
\newlabel{fig:maze2-case1-state2}{{8c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.2018 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.6692 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.5693 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.6134 \relax }{figure.caption.12}{}}
\newlabel{sub@fig:maze2-case1-state2}{{c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.2018 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.6692 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.5693 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.6134 \relax }{figure.caption.12}{}}
\newlabel{fig:maze2-case1-state3}{{8d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: 0.1001 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.1958 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.4426 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.0384 \relax }{figure.caption.12}{}}
\newlabel{sub@fig:maze2-case1-state3}{{d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: 0.1001 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.1958 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.4426 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.0384 \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.4}Maze 2 - Study case 2}{4}{subsubsection.8.2.4}\protected@file@percent }
\newlabel{fig:maze2-case2-states}{{9a}{4}{Maze 2: Study case 2 \vspace {12mm}\relax }{figure.caption.13}{}}
\newlabel{sub@fig:maze2-case2-states}{{a}{4}{Maze 2: Study case 2 \vspace {12mm}\relax }{figure.caption.13}{}}
\newlabel{fig:maze2-case2-state1}{{9b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.5848 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.6763 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.4808 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.2210 \relax }{figure.caption.13}{}}
\newlabel{sub@fig:maze2-case2-state1}{{b}{4}{State 1 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.5848 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.6763 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: -0.4808 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.2210 \relax }{figure.caption.13}{}}
\newlabel{fig:maze2-case2-state2}{{9c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.0098 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.2776 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.2342 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0314 \relax }{figure.caption.13}{}}
\newlabel{sub@fig:maze2-case2-state2}{{c}{4}{State 2 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.0098 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: -0.2776 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.2342 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: 0.0314 \relax }{figure.caption.13}{}}
\newlabel{fig:maze2-case2-state3}{{9d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.2766 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: 0.0523 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.9958 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.1527 \relax }{figure.caption.13}{}}
\newlabel{sub@fig:maze2-case2-state3}{{d}{4}{State 3 \\ \scriptsize \hspace *{5mm} $\boldsymbol {\cdot }$ left: -0.2766 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ up: 0.0523 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ right: 0.9958 \\ \hspace *{5mm} $\boldsymbol {\cdot }$ down: -0.1527 \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}RMS during the training}{5}{subsection.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Explique como é definida a função de erro quadrático médio usada no treinamento.}{5}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Inicialmente, devemos relembrar a equação de Bellman. Queremos achar a função Q-valor ótima, $Q^*$, que satisfaça a seguinte equação:}{5}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A política ótima $\pi ^*$ é dada se tomarmos a melhor ação de acordo com os valores da função $Q^*$.}{5}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Para resolver a equação anterior, temos um algoritmo iterativo dado por:}{5}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Quando $i$ tende a infinito, temos que $Q_i$ tende a $Q^*$.}{5}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Entretanto, essa abordagem não é escalável. Assim o que se faz é usar uma rede neural para aprender e estimar a função Q-valor, sintetizando portanto, um mapeamento entre os estados e os q-valores.}{5}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Faremos então:}{5}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Onde $\theta $ representa os parâmetros do modelo (pesos da rede neural).}{5}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Assim, tomando $y_i$ como a saída da rede neural e $L_i(\theta _i)$ a função de perda usada durante seu treinamento, podemos retomar a equação de Bellman aproximando o lado direito com o lado esquerdo:}{5}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{E é justamente assim que é definida a função de erro quadrático médio usado no treinamento. Procura-se um mapeamento entre os estados, usado como entrada da rede neural (neste caso é o panorama do labirinto), e a a função Q-valor ótima. Ao minizarmos o erro quadrático médio entre a saída da rede e função Q-valor parametrizada por theta, estamos na verdade forçando que o lado esquerdo da equação de Bellman seja igual ao lado direito. Conforme o agente se movimenta e explora o ambiente, atua-se no vetor de pesos através de técnicas de gradiente, e com isso chegamos em um mapeamento onde a saída da rede neural representa a função Q-valor ótima aproximada.}{5}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Para finalizar, usando como gancho para a resposta do próximo item, temos que a entrada da rede (inputs) o estado do ambiente e a saída da rede (targets) calculada como a recompensa dada pela ação tomada anteriormente mais o fator de desconto (gamma) multiplicado pelo máximo de $Q(s',a')$ (que representa o máximo da saída do próximo estado, ou apenas a recompensa em caso de game over).}{5}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Experience replay}{6}{subsection.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Explique como é trabalhada a técnica de experience replay.}{6}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Para se trabalhar com a técnica de experience replay, é proposta uma classe denominada Experience. Nesta classe temos o ``construtor" da classe \_\_init\_\_ (magic method, ou ainda ``dunder``) e três métodos: remember, predict e get\_data.}{6}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A principal ideia aqui é usar uma memória para armazenar episódios. Um episódio é composto de uma lista com cinco elementos:}{6}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Assim, para cada movimento do rato, temos um episódio que podemos inserir em uma memória. Conforme essa memória vai enchendo, defini-se um limite para deletar episódios mais antigos armazenados. Neste caso em específico, adotou-se uma memória de tamanho padrão 1000, mas definindo-a como 8 vezes o tamanho do labirinto na chamada do treinamento da rede neural.}{6}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{O método remember é chamado após cada movimento do agente, sendo sua função armazenar as informações daquele episódio na memória. O método get\_data é usado para pegar da memória a entrada (inputs) e saída (targets) que será usado no treinamento da rede neural, sendo que o número de amostras retornado por get\_data é definido como o mínimo entre o tamanho da memória e 50 (data\_size). E é esse processo que caracteriza a técnica experience replay, armazenando experiências recentes do agente (com a premissa de quanto mais ele se movimenta no ambiente, melhor vai ficando a predição da rede neural e portanto seus próximos movimentos) e usando dessas experiências para o treinamento, dado que a solução do problema trata-se de um processo iterativo.}{6}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Inicialmente, a saída da rede neural produzirá resultados aleatórios, mas conforme o treinamento for avançando e os parâmetros ajustados adequadamente, sua saída vai convergindo para a solução da equação de Bellman.}{6}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Question 9: GAN}{7}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The Jupyter notebook related to this section with the results presented here can be opened in Google Colab environment with following link:\\}{7}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}MNIST}{7}{subsection.9.1}\protected@file@percent }
\newlabel{fig:mnist-epoch0}{{10a}{7}{First image\relax }{figure.caption.32}{}}
\newlabel{sub@fig:mnist-epoch0}{{a}{7}{First image\relax }{figure.caption.32}{}}
\newlabel{fig:mnist-epoch1000}{{10b}{7}{After 1,000 epochs\relax }{figure.caption.32}{}}
\newlabel{sub@fig:mnist-epoch1000}{{b}{7}{After 1,000 epochs\relax }{figure.caption.32}{}}
\newlabel{fig:mnist-epoch10000}{{10c}{7}{After 10,000 epochs\relax }{figure.caption.32}{}}
\newlabel{sub@fig:mnist-epoch10000}{{c}{7}{After 10,000 epochs\relax }{figure.caption.32}{}}
\newlabel{fig:mnist-epoch20000}{{10d}{7}{After 20,000 epochs\relax }{figure.caption.32}{}}
\newlabel{sub@fig:mnist-epoch20000}{{d}{7}{After 20,000 epochs\relax }{figure.caption.32}{}}
\newlabel{fig:mnist-epoch30000}{{10e}{7}{After 30,000 epochs\relax }{figure.caption.32}{}}
\newlabel{sub@fig:mnist-epoch30000}{{e}{7}{After 30,000 epochs\relax }{figure.caption.32}{}}
\newlabel{fig:mnist-epoch50000}{{10f}{7}{After 50,000 epochs\relax }{figure.caption.32}{}}
\newlabel{sub@fig:mnist-epoch50000}{{f}{7}{After 50,000 epochs\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces GAN trained for MNIST dataset\relax }}{7}{figure.caption.32}\protected@file@percent }
\newlabel{fig:gan-mnist}{{10}{7}{GAN trained for MNIST dataset\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Fashion MNIST}{7}{subsection.9.2}\protected@file@percent }
\newlabel{fig:fashion_mnist-epoch0}{{11a}{7}{First image\relax }{figure.caption.33}{}}
\newlabel{sub@fig:fashion_mnist-epoch0}{{a}{7}{First image\relax }{figure.caption.33}{}}
\newlabel{fig:fashion_mnist-epoch1000}{{11b}{7}{After 1,000 epochs\relax }{figure.caption.33}{}}
\newlabel{sub@fig:fashion_mnist-epoch1000}{{b}{7}{After 1,000 epochs\relax }{figure.caption.33}{}}
\newlabel{fig:fashion_mnist-epoch10000}{{11c}{7}{After 10,000 epochs\relax }{figure.caption.33}{}}
\newlabel{sub@fig:fashion_mnist-epoch10000}{{c}{7}{After 10,000 epochs\relax }{figure.caption.33}{}}
\newlabel{fig:fashion_mnist-epoch20000}{{11d}{7}{After 20,000 epochs\relax }{figure.caption.33}{}}
\newlabel{sub@fig:fashion_mnist-epoch20000}{{d}{7}{After 20,000 epochs\relax }{figure.caption.33}{}}
\newlabel{fig:fashion_mnist-epoch30000}{{11e}{7}{After 30,000 epochs\relax }{figure.caption.33}{}}
\newlabel{sub@fig:fashion_mnist-epoch30000}{{e}{7}{After 30,000 epochs\relax }{figure.caption.33}{}}
\newlabel{fig:fashion_mnist-epoch50000}{{11f}{7}{After 50,000 epochs\relax }{figure.caption.33}{}}
\newlabel{sub@fig:fashion_mnist-epoch50000}{{f}{7}{After 50,000 epochs\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces GAN trained for fashion MNIST dataset\relax }}{7}{figure.caption.33}\protected@file@percent }
\newlabel{fig:gan-fashion_mnist}{{11}{7}{GAN trained for fashion MNIST dataset\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Question 10: NLP}{8}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The Jupyter notebook related to this section with the results presented here can be opened in Google Colab environment with following link:\\}{8}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}word2vec}{8}{subsection.10.1}\protected@file@percent }
\newlabel{fig:cbow}{{12a}{8}{CBOW\relax }{figure.caption.36}{}}
\newlabel{sub@fig:cbow}{{a}{8}{CBOW\relax }{figure.caption.36}{}}
\newlabel{fig:skip-gram}{{12b}{8}{skip-gram\relax }{figure.caption.36}{}}
\newlabel{sub@fig:skip-gram}{{b}{8}{skip-gram\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Architectures used in word2vec\relax }}{8}{figure.caption.36}\protected@file@percent }
\newlabel{fig:word2vec}{{12}{8}{Architectures used in word2vec\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {paragraph}{O word2vec, proposto por \href  {https://github.com/ito-rafael/machine-learning/blob/master/papers/NLP/2013\%20-\%20\%5Bword2vec\%5D\%20Efficient\%20Estimation\%20of\%20Word\%20Representations\%20in\%20Vector\%20Space\%20\%5BGoogle\%20Inc\%5D.pdf}{(Mikolov et al., 2013)} é uma ferramenta que fornece uma implementação eficiente das arquiteturas CBOW (continuous bag-of-words) e skip-gram para computar representação de vetores de palavras. Um resumo de uma página deste artigo feito por mim pode ser encontrado no seguinte \href  {https://github.com/ito-rafael/machine-learning/blob/master/one-page\%20papers\%20summary/2013\%20-\%20\%5Bword2vec\%5D\%20Efficient\%20Estimation\%20of\%20Word\%20Representations\%20in\%20Vector\%20Space\%20\%5BGoogle\%20Inc\%5D.pdf}{link}. O código do wordvec está disponível em \href  {https://code.google.com/archive/p/word2vec/}{https://code.google.com/archive/p/word2vec/}.}{8}{figure.caption.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Resumidamente, o modelo CBOW tenta prever a palavra atual, baseada no contexto de algumas palavras anteriores e algumas palavras posteriores. Já o modelo Skip-gram tenta maximizar a classificação de uma palavra baseado em outra palavra na mesma frase.}{8}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Além dessas duas arquiteturas propostas, o artigo também apresenta medidas de similaridades sintáticas e semânticas entre palavras (feitas algebricamente), a criação do dataset ``Semantic-Syntactic Word Relationship test set" e uma forma de treinamento paralelo implementada em um framework chamado “DistBelief".}{8}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Em termos práticos, o que se consegue com o word2vec é uma representação de palavras em um espaço de dimensão reduzida (um vetor no ${\rm  I\tmspace  -\thinmuskip {.1667em}R^{300}}$ por exemplo). Com isso, elimina-se a esparsidade da técnica anterior denominada bag-of-words, one tinha-se uma representação one-hot das palavras, isto é, a entrada da rede neural tinha o tamanho do vocabulário usado.}{8}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Esses vetores são denominados de word embeddings e são usados na grande maioria de arquiteturas SOTA (state-of-the-art). Por exemplo, na arquitetura BERT, usa-se três tipos de embeddings: embedding posicional, embedding de segmento e embedding de palavras.}{8}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Por fim, é interessante ressaltar as relações entre embeddings obtidas através de simples operações algébricas. Por exemplo, se considerarmos a relação entre embeddings de palavras de país e capital, temos a seguinte relação: Paris - France + Italy = Rome. Isto é, operando com os embeddings das palavras Paris, France e Italy, temos como resultado um vetor, sendo que a palavra mais próxima desse vetor resultante é o embedding da palavra Rome. Um outro exmplo clássico é a operação entres os vetores das palavra King - Man + Woman. O embedding mais próximo deste resultado é o da palavra Queen.}{9}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Um outro projeto semelhante é o GloVe, proposto em \href  {https://github.com/ito-rafael/machine-learning/blob/master/papers/NLP/2014\%20-\%20\%5BGloVe\%5D\%20GloVe:\%20Global\%20Vectors\%20for\%20Word\%20Representation\%20\%5BStanford\%20University\%5D\%20(Pennington\%20et\%20al.\%2C\%202014).pdf}{(Pennington et al., 2014)}, que também propõe vetores para representação de palavras. Um exemplo interessante pode ser encontrado na \href  {https://nlp.stanford.edu/projects/glove/}{página inicial do projeto}, onde é mostrado que as palavras cujos embedding são mais próximos do embedding da palavra frog são: frogs, toad, litoria, leptodactylidae, rana, lizard e eleutherodactylus.}{9}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}t-SNE}{9}{subsection.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces T-SNE 1\relax }}{9}{figure.caption.43}\protected@file@percent }
\newlabel{fig:tsne1}{{13}{9}{T-SNE 1\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces T-SNE 2\relax }}{10}{figure.caption.44}\protected@file@percent }
\newlabel{fig:tsne2}{{14}{10}{T-SNE 2\relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Results discussion}{10}{subsection.10.3}\protected@file@percent }
