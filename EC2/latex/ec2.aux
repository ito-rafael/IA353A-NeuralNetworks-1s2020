\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Transferência negativa}{2}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transferência negativa é quando tem-se uma piora de performance ao compartilhar informação de tarefas em MTL. Isso ocorre quando as tarefas envolvidas não são relacionadas. Ou seja, para ser possível trabalhar com \emph  {multitask learning}, as tarefas envolvidas devem ter uma relação próxima. Caso os termos na função de perda para diferentes tarefas estejam em escalas diferentes, o resultado também pode não ser positivo em MTL.}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Camadas compartilhadas}{2}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Uma das estratégias usada em MTL consiste em incluir na função custo a ser otimizada as perdas de cada uma das tarefas envolvidas, por exemplo com uma soma ponderada (para o caso de as escalas da perdas serem diferentes). Assim, o ajuste dos pesos das camadas compartilhadas da arquitetura de MTL mostrada na figura \ref  {fig:q7} consiste em apresentar para a rede padrões das tarefas consideradas, calcular o erro na saída da tarefa em questão e fazer o uso do \emph  {backpropagation} normalmente para atualização dos pesos (se mini batches forem usados, misturar dados das tarefas para formar os mini batches pode ajudar no treinamento).}{2}{section*.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Abordagem de compartilhamentos de parâmetros \emph  {Hard}\relax }}{2}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:q7}{{2}{2}{Abordagem de compartilhamentos de parâmetros \emph {Hard}\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Se treinarmos cada tarefa de aprendizado individualmente, na prática estamos ignorando informações das outras tarefas relacionadas que poderia ajudar ainda mais na métrica da tarefa em treinamento. Quando usamos todas essas informações, estamos compartilhando representações entre as tarefas relacionadas e isso faz com o que o modelo generalize melhor na tarefa original.}{2}{figure.caption.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{De fato, esta é uma das vantagens em se usar MTL. Conforme citado no artigo \href  {https://arxiv.org/pdf/1706.05098.pdf}{(Ruder, 2017)}, recomendando como leitura de apoio para a resposta desta questão, \href  {https://link.springer.com/content/pdf/10.1023/A:1007327622663.pdf}{(Baxter, 1997)} mostra que o risco de \emph  {overfitting} nos parâmetros das camadas compartilhadas é de ordem N (onde N é o número de tarefas) vezes menor do que o risco de \emph  {overfitting } nas camadas de saída específicas para cada tarefa. E isso faz sentido, pois quanto mais tarefas considerarmos simultaneamente, mais o modelo precisa encontrar uma representação que capture todas as tarefas, e portanto menor é a chance de \emph  {overfitting}.}{2}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Uma outra forma de enxergar MTL, também recorrendo à leitura de apoio, é olhar para MTL como uma forma de transferência indutiva, que melhora o modelo introduzindo um \emph  {bias} indutivo. Para o caso de MTL, esse \emph  {bias} indutivo é fornecido pelas tarefas auxiliares, e isso faz com que o modelo dê preferência para hipóteses que explicam mais de uma tarefa, o que geralmente leva a soluções que generalizam melhor.}{2}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Por fim, um último fato relevante a ser levantado é que mesmo que a função custo a ser otimizada seja apenas de uma tarefa, incluir tarefas auxiliares (que tenham alguma relação com a tarefa original) pode melhorar o desempenho na tarefa original, por conta de uma melhor representação dos dados nas camadas compartilhadas.}{3}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}MALSAR}{3}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Em \emph  {machine learning}, para problemas de regressão e classificação geralmente temos o seguinte problema de otimização para ser resolvido:}{3}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Nesta equação, $W$ representa os parâmetros a serem ajustados a partir de dados durante a etapa de treinamento, $\mathcal  {L}(W)$ representa a função de perda e $\Omega (W)$ o termo de regularização.}{3}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{No contexto de MTL, $W$ continua sendo os parâmetros ajustáveis. Entretanto, como estamos trabalhando com mais de uma tarefa, podemos ter um $W$ para cada tarefa, sendo que parte dos parâmetros de $W$ são compartilhados entre as tarefas (por exemplo como no caso da figura \ref  {fig:q7} do item anterior). Assim, na função de perda $\mathcal  {L}(W)$ devemos incorporar os erros associados a cada uma das tarefas, podendo ser uma soma ponderada, por exemplo. $\Omega (W)$ continua sendo o termo de regularização, mas que agora incorpora a relação entre as tarefas. Isto é, diferentes suposições a cerca do tipo de relações entre as tarefas leva a diferente termos de regularização.}{3}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Em seguida, apresentaremos uma conformação possível para os termos de otimização da equação anterior:}{3}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Essa formulação de MTL considera o método de regularização Lasso, que penaliza a norma $\ell _1$ de $W$. Esse tipo de regularização é tipicamente usado para introduzir esparsidade no modelo, forçando alguns parâmetros a zero e reduzindo a complexidade do modelo. Para a extensão da formulação de STL (\emph  {Single-Task Learning}) para MTL temos que o parâmetro que controla a esparsidade é compartilhado entre todas as tarefas, assumindo assim que diferentes tarefas apresentam o mesmo parâmetro de esparsidade.}{3}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Na equação anterior, temos:}{3}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{O que foi apresentado vale para a regularização Lasso, podendo ser extendida para a regularização de quadrados mínimos alterando $\Omega (W)$ para $\rho _{L2}||W||_F^2$, ou ainda para elastic net somando este último termo ao apresentado para Lasso (ou seja, $\Omega (W) = \rho _1 ||W||_1 + \rho _{L2}||W||_F^2$).}{3}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Considerando a camada $q$ de uma rede neural MLP, temos:}{4}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Onde:}{4}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Calculando a variância de ambos lados da equação anterior, temos:}{4}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Devemos agora fazer algumas considerações:}{4}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Continuando o desenvolvimento da equação anterior:}{4}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A partir de i), temos:}{4}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Se duas variáveis são independentes entre si, temos a igualdade:\\ \href  {https://en.wikipedia.org/wiki/Variance\#Product_of_independent_variables}{https://en.wikipedia.org/wiki/Variance\#Product\_of\_independent\_variables}:}{4}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Vamos agora abrir o produto das matrizes $W$ e $x$ em uma soma dos produtos de seus termos $w_i$ e $x_i$. Usando também a consideração dada por ii) e sabendo que $b$ é uma constante (e portanto sua variância é zero), temos que:}{4}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A partir de iii) e iv), temos que $\mathbb  {E}(w_i) = 0$ e $\mathbb  {E}(x_i) = 0$, sendo ambos $W$ e $x$ variáveis i.i.d. Assim:}{5}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Queremos provar que $b = \sqrt  {\frac  {3}{n^{[q-1]}}}$ para que a variância da entrada da camada $q$ seja igual a variância da camada $q-1$.}{5}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sabendo que a variância de uma variável aleatória que segue uma distribuição uniforme entre $a$ e $b$, isto é, $X \sim \mathbb  {U}[a,b]$, é dada por: $Var(X) = \frac  {(b-a)^2}{12}$ (\href  {https://proofwiki.org/wiki/Variance_of_Continuous_Uniform_Distribution}{prova}). Temos:}{5}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Como queremos $Var(x^{[q]}) = Var(x^{[q-1]})$, temos:}{5}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Ou seja, os pesos $W$ devem ser inicializados com uma distribuição uniforme segundo:}{5}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Principais seções do padrão de documentação}{6}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{As principais seções do padrão de documentação de datasets são mostradas na seção 3 do artigo, entitulada ``Questions and Workflow''. Os itens desta seção, assim como uma breve descrição são apresentados a seguir:}{6}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Dois exemplos de datasheet para dataset são mostrados no apêndice do artigo. Um para o dataset ``Labeled Faces in the Wild'' e outro para o dataset ``Pang and Lee’s polarity''.}{6}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Artigos com propósitos similares}{6}{subsection.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.1}Artigo 1}{6}{subsubsection.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2}Artigo 2}{6}{subsubsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}EfficientNet}{7}{subsection.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{O artigo \href  {https://arxiv.org/pdf/1905.11946.pdf}{(Tan \& Le, 2019)} propõe uma forma de escalar modelos baseados em redes convolucionais (ConvNets), como por exemplo MobileNets e ResNet, levando em conta três parâmetros avaliados conjuntamente: profundidade, largura e resolução. Adicionalmente, os autores usam um método de NAS (\emph  {neural architecture search}) para encontrar um modelo base (baseline), para em seguida usar o método de escalamento proposto e obter uma família de modelos denominada \emph  {EfficientNets}, cujos resultados são impressionantes, sendo mais eficientes em termos de custo computacional (modelos menores e mais rápidos) e performance, com resultados melhores atingindo o estado da arte (SOTA) para base de dados como ImageNet, CIFAR-100 e outras.}{7}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Supondo que se queira um modelo maior que use $2^N$ mais recursos, propõe-se aumentar a rede multiplicando os três parâmetros pelas seguintes constantes: profundidade multiplicada por $\alpha ^N$, largura multiplicada por $\beta ^N$ e tamanho da imagem (resolução) por $\gamma ^N$, onde $\alpha $, $\beta $ e $\gamma $ são determinados através de um grid search no modelo original.}{7}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Na seção 3 do artigo, os autores mostram que o escalamento dos três parâmetros aumentam a performance dos modelos, mas cada um seguindo sua própria curva de saturação (figura 3 do artigo). Assim, eles chegam na primeira observação. A segunda observação foi obtida através dos experimentos cujos resultados são mostrados na figura 4 do artigo. Aqui é concluído que para uma melhor acurácia e eficiência, é necessário um balanceamento entre os fatores de escala de largura, profundidade e resolução.}{7}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{O método de escalamento proposto é mostrado a seguir:}{7}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sujeito a:}{7}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{O modelo base, denominado EfficientNet, foi obtido através de uma busca (NAS) multi-objetiva, procurando otimizar tanto a acurácia quanto FLOPS (operações de ponto flutuante por segundo). A função objetivo é dada por: $ACC(m) \times [FLOPS(m)/T]^w$, onde $ACC(m)$ e $FLOPS(m)$ é a acurária e FLOPS do modelo $m$, $T$ é o FLOPS alvo e $w$ controla o \emph  {tradeoff} entre acurária e FLOPS. Tomando $w = -0.07$, chega-se no modelo EfficientNet-B0.}{7}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A partir do modelo EfficientNet-B0, toma-se $\phi =1$ (dobro de recursos) e busca-se as constantes através de um \emph  {grid search}. Encontra-se $\alpha =1.2$, $\beta =1.1$ e $\gamma =1.15$, satisfazendo a restrição $\alpha \cdot \beta ^2 \cdot \gamma ^2 \approx 2$. Em seguida, essas constantes são usadas para escalar diferentes modelos alterando o valor de $\phi $, obtendo-se os modelos EfficientNet-B1 até B7. Além destes modelos, MobileNets e ResNets também foram escaladas seguindo essa regra.}{7}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A partir da seção 5 do artigo, são descritos os experimentos e resultados, discussões e conclusão. Conforme descrito no início da resposta desta questão, os resultados obtidos são impressionantes, ganhando tanto em performance (custo computacional) quanto em desempenho (acurária), atingindo um novo SOTA na área de visão computacional e ConvNets.}{7}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}FixEfficientNet}{8}{subsection.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{O segundo artigo \href  {https://arxiv.org/pdf/2003.08237.pdf}{(Touvron et al., 2020)} é na verdade uma nota que complementa o artigo ``\href  {https://arxiv.org/pdf/1906.06423.pdf}{Fixing the train-test resolution discrepancy}'', que introduz o método denominado FixRes.}{8}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{O artigo original mostra que as técnicas de \emph  {data-augmentation} usadas até então induziam uma discrepância entre o tamanhos dos objetos visto pelo classificador durante o treinamento e durante a fase de teste. Assim, os autores propõe uma estratégia que otimiza a performance do classificador, empregando diferentes resoluções em teste e treinamento. Isso é feito através de um \emph  {fine-tuning} da rede na resolução de teste.}{8}{section*.44}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparação entre diversas redes com e sem a aplicação do método FixRes\relax }}{8}{figure.caption.46}\protected@file@percent }
\newlabel{fig:q10}{{3}{8}{Comparação entre diversas redes com e sem a aplicação do método FixRes\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {paragraph}{A nota que complementa o artigo original toma as diversas redes renomadas, dentre elas as EfficientNets do item anterior, e aplica o método FixRes para obter uma família de redes denominadas FixEfficientNet. Os resultados podem ser vistos na figura \ref  {fig:q10}.}{8}{figure.caption.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Como podemos ver, em um curto período de tempo temos novos modelos SOTA. Alguns podem vir de arquiteturas novas (ex: EfficientNet em ConvNets e Transformers em NLP), outros de melhorias feitas na metodologia a partir de modelos já existentes (ex: escalamento apresentado no artigo da EfficientNet e método FixRes).}{8}{section*.47}\protected@file@percent }
